[
    {
        "Name": "WebRTC",
        "Config": "PortMin = 0\nPortMax = 0\nPLI = 2000\n",
        "ReadMe": "# webrtc 插件\n\n提供通过网页发布视频到monibuca，以及从monibuca拉流通过webrtc进行播放的功能\n\n# 基本原理\n\n通过浏览器和monibuca交换sdp信息，然后读取rtp包或者发送rtp的方式进行\n\n# API\n- /api/webrtc/play?streamPath=live/rtc\n用于播放live/rtc的流，需要在请求的body中放入sdp的json数据，这个接口会返回服务端的sdp数据\n- /api/webrtc/publish?streamPath=live/rtc\n同上",
        "Version": "v3.0.1",
        "HotConfig": null
    },
    {
        "Name": "TS",
        "Config": "BufferLength = 2048\nPath = \"resource\"\n",
        "ReadMe": "# TS插件\n处理TS数据的插件\n\n# 功能\n\n1. 通过Publish发布一个TS流，然后通过Feed方法填入TS数据即可\n2. 通过PublishDir可以读取服务器上文件夹内的所有ts文件进行发布\n\n# 默认配置\n\n```toml\n[TS]\nBufferLength = 2048\nPath         = \"ts\"\n```\n- BufferLength指的是解析TS流的时候的缓存大小，单位是PES包的个数\n- Path 指存放ts的目录\n\n## API\n\n- `/api/ts/list` 罗列所有ts文件\n- `/api/ts/publish?streamPath=live/rtc` 开始将文件夹内的ts文件逐个读取，发布成一个直播流\n",
        "Version": "v3.0.0",
        "HotConfig": null
    },
    {
        "Name": "HLS",
        "Config": "Fragment = 10\nWindow = 2\nEnableWrite = false\nEnableMemory = false\nFilter = \"\"\nPath = \"resource\"\n",
        "ReadMe": "# m7s核心引擎\r\n\r\n该项目为m7s的引擎部分，该部分逻辑是流媒体服务器的核心转发逻辑。仅包含最基础的功能，不含任何网络协议部分，但包含了一个插件的引入机制，其他功能均由插件实现\r\n\r\n# 引擎配置\r\n```toml\r\n[Engine]\r\nEnableAudio = true\r\nEnableVideo = true\r\n# 发布流默认过期时间单位秒\r\nPublishTimeout = 60\r\n# 自动关闭触发后延迟的秒数(期间内如果有新的订阅则取消触发关闭)\r\nAutoCloseDelay = 10\r\n# 启用RTP包乱序重排\r\nRTPReorder = false\r\n```\r\n\r\n# 引擎的基本功能\r\n- 引擎初始化会加载配置文件，并逐个调用插件的Run函数\r\n- 具有发布功能的插件，新建一个Stream对象，这个Stream对象随后可以被订阅\r\n- Stream对象中含有两个列表，一个是VideoTracks一个是AudioTracks用来存放视频数据和音频数据\r\n- 每一个VideoTrack或者AudioTrack中包含一个RingBuffer，用来存储发布者提供的数据，同时提供订阅者访问。\r\n- 具有订阅功能的插件，会通过GetStream函数获取到一个流，然后选择VideoTracks、AudioTracks里面的RingBuffer进行连续的读取\r\n\r\n# 发布插件如何发布流\r\n\r\n以rtmp协议为例子\r\n```go\r\nstream = \u0026engine.Stream{Type: \"RTMP\", StreamPath: streamPath}\r\nif stream.Publish() {\r\n  absTs := make(map[uint32]uint32)\r\n  vt := stream.NewVideoTrack(0)\r\n  at := stream.NewAudioTrack(0)\r\n  rec_audio = func(msg *Chunk) {\r\n    if msg.ChunkType == 0 {\r\n      absTs[msg.ChunkStreamID] = 0\r\n    }\r\n    if msg.Timestamp == 0xffffff {\r\n      absTs[msg.ChunkStreamID] += msg.ExtendTimestamp\r\n    } else {\r\n      absTs[msg.ChunkStreamID] += msg.Timestamp\r\n    }\r\n    at.PushByteStream(absTs[msg.ChunkStreamID], msg.Body)\r\n  }\r\n  rec_video = func(msg *Chunk) {\r\n    if msg.ChunkType == 0 {\r\n      absTs[msg.ChunkStreamID] = 0\r\n    }\r\n    if msg.Timestamp == 0xffffff {\r\n      absTs[msg.ChunkStreamID] += msg.ExtendTimestamp\r\n    } else {\r\n      absTs[msg.ChunkStreamID] += msg.Timestamp\r\n    }\r\n    vt.PushByteStream(absTs[msg.ChunkStreamID], msg.Body)\r\n  }\r\n  err = nc.SendMessage(SEND_STREAM_BEGIN_MESSAGE, nil)\r\n  err = nc.SendMessage(SEND_PUBLISH_START_MESSAGE, newPublishResponseMessageData(nc.streamID, NetStream_Publish_Start, Level_Status))\r\n} else {\r\n  err = nc.SendMessage(SEND_PUBLISH_RESPONSE_MESSAGE, newPublishResponseMessageData(nc.streamID, NetStream_Publish_BadName, Level_Error))\r\n}\r\n```\r\n默认会创建一个VideoTrack和一个AudioTrack\r\n当我们接收到数据的时候就可以朝里面填充物数据了\r\n\r\n在填充数据之前，需要获取到SPS和PPS，然后设置好，因为订阅者需要先发送这个数据\r\n然后通过Track到Push函数将数据填充到RingBuffer里面去\r\n\r\n# 订阅插件如何订阅流\r\n\r\n```go\r\nsub := Subscriber{ID: r.RemoteAddr, Type: \"FLV\", Ctx2: r.Context()}\r\nif err := sub.Subscribe(stringPath); err == nil {\r\n  vt, at := sub.WaitVideoTrack(), sub.WaitAudioTrack()\r\n  var buffer bytes.Buffer\r\n  if _, err := amf.WriteString(\u0026buffer, \"onMetaData\"); err != nil {\r\n    return\r\n  }\r\n  if vt != nil {\r\n    codec.WriteFLVTag(w, codec.FLV_TAG_TYPE_VIDEO, 0, vt.ExtraData.Payload)\r\n    sub.OnVideo = func(ts uint32, pack *VideoPack) {\r\n      codec.WriteFLVTag(w, codec.FLV_TAG_TYPE_VIDEO, ts, pack.Payload)\r\n    }\r\n  }\r\n  if at != nil {\r\n    if at.CodecID == 10 {\r\n      codec.WriteFLVTag(w, codec.FLV_TAG_TYPE_AUDIO, 0, at.ExtraData)\r\n    }\r\n    sub.OnAudio = func(ts uint32, pack *AudioPack) {\r\n      codec.WriteFLVTag(w, codec.FLV_TAG_TYPE_AUDIO, ts, pack.Payload)\r\n    }\r\n  }\r\n  sub.Play(at, vt)\r\n}\r\n```\r\n- 在发送数据前，需要先发送音视频的序列帧",
        "Version": "",
        "HotConfig": null
    },
    {
        "Name": "Jessica",
        "Config": "ListenAddr = \"\"\nCertFile = \"\"\nKeyFile = \"\"\nListenAddrTLS = \"\"\n",
        "ReadMe": "# jessica 插件\r\nwebsocket raw data protocol plugin for monibuca\r\n\r\n通过Websocket传输音视频数据，使用Jessibuca播放器进行播放。\r\n\r\n## 插件地址\r\n\r\ngithub.com/Monibuca/plugin-jessica\r\n\r\n## 配置\r\n\r\n可配置WS协议和WSS协议监听地址端口\r\n\r\n```toml\r\n[Jessica]\r\nListenAddr = \":8080\"\r\nCertFile = \"../foo.cert\"\r\nKeyFile  = \"../foo.key\"\r\nListenAddrTLS = \":8088\"\r\n```\r\n\r\n- 如果不设置ListenAddr和ListenAddrTLS，将共用网关的端口监听\r\n\r\n## 协议说明\r\n\r\n该插件提供两种格式的协议供播放器播放。\r\n\r\n### WS-RAW\r\n\r\n- 地址格式：ws://[HOST]/jessica/[streamPath]\r\n\r\n- 该协议传输的是私有格式，第一个字节代表音视频，1为音频，2为视频，后面跟4个字节的时间戳，然后接上字节流（RTMP的VideoTag或AudioTag）\r\n\r\n### WS-FLV\r\n\r\n- 地址格式：ws://[HOST]/jessica/[streamPath].flv\r\n- 该协议传输的flv格式的文件流\r\n",
        "Version": "",
        "HotConfig": null
    },
    {
        "Name": "LogRotate",
        "Config": "Path = \"logs\"\nSize = 0\nDays = 1\nFormatter = \"2006-01-02T15\"\n",
        "ReadMe": "# LogRotate插件\n\n日志分割插件，带UI界面，可以实时查看日志输出，和日志查询\n日志查询暂时只支持linux系统\n\n## 默认配置\n```toml\n[LogRotate]\nPath = \"log\"\nSize = 0\nDays = 1\nFormatter = \"2006-01-02T15\"\n```\n其中Path代表生成日志的目录\nSize代表按大小分割，单位是字节，如果为0，则按时间分割\nDays代表按时间分割，单位是天，即24小时\nFormatter日志文件名格式化，按照go layout格式化，默认按照小时\n\n## API接口\n\n- `/api/logrotate/tail` 监听日志输出，该请求是一个SSE（server-sent Event）\n- `/api/logrotate/find` 查找日志，目前只支持linux系统（使用grep）\n- `/api/logrotate/list` 列出所有日志文件\n- `/api/logrotate/open?file=xxx` 查看日志内容，入参是文件名\n- `/api/logrotate/download?file=xxx` 下载某个日志，入参是文件名",
        "Version": "v3.0.0-20210710104346-3db68431dcab",
        "HotConfig": null
    },
    {
        "Name": "Summary",
        "Config": "SampleRate = 1\n",
        "ReadMe": "# Summary插件\n\n对系统的信息进行采样，支持级联采样，即从服务器会向主服务器报告数据\n\n\u003e 如果没有订阅者则不进行采集，节省系统资源\n\n## 默认配置\n\n```toml\n[Summary]\nSampleRate = 1\n```\n- SampleRate 采样率，单位秒，即每一秒采样一次\n\n## 数据结构\n\n```go\ntype ServerSummary struct {\n\tAddress string\n\tMemory  struct {\n\t\tTotal uint64\n\t\tFree  uint64\n\t\tUsed  uint64\n\t\tUsage float64\n\t}\n\tCPUUsage float64\n\tHardDisk struct {\n\t\tTotal uint64\n\t\tFree  uint64\n\t\tUsed  uint64\n\t\tUsage float64\n\t}\n\tNetWork     []NetWorkInfo\n\tStreams     []*Stream\n\tlastNetWork []NetWorkInfo\n\tref         int\n\tcontrol     chan bool\n\treportChan  chan *ServerSummary\n\tChildren    map[string]*ServerSummary\n}\n```\n\n\n## API\n\n- `/api/summary` 获取采样数据，这个接口返回一个SSE\n\n## 上报逻辑\n\n```mermaid\ngraph LR\n    从服务器 --上报--\u003e 主服务器\n    主服务器 --推送--\u003e 用户页面\n```",
        "Version": "v0.0.0-20210821070131-2261e0efb7b9",
        "HotConfig": null
    },
    {
        "Name": "RTSP",
        "Config": "ListenAddr = \":554\"\nUDPAddr = \":8000\"\nRTCPAddr = \":8001\"\nTimeout = 0\nReconnect = true\nReadBufferSize = 2048\n\n[AutoPullList]\n  \"live/1\" = \"rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mp4\"\n",
        "ReadMe": "# m7s核心引擎\r\n\r\n该项目为m7s的引擎部分，该部分逻辑是流媒体服务器的核心转发逻辑。仅包含最基础的功能，不含任何网络协议部分，但包含了一个插件的引入机制，其他功能均由插件实现\r\n\r\n# 引擎配置\r\n```toml\r\n[Engine]\r\nEnableAudio = true\r\nEnableVideo = true\r\n# 发布流默认过期时间单位秒\r\nPublishTimeout = 60\r\n# 自动关闭触发后延迟的秒数(期间内如果有新的订阅则取消触发关闭)\r\nAutoCloseDelay = 10\r\n# 启用RTP包乱序重排\r\nRTPReorder = false\r\n```\r\n\r\n# 引擎的基本功能\r\n- 引擎初始化会加载配置文件，并逐个调用插件的Run函数\r\n- 具有发布功能的插件，新建一个Stream对象，这个Stream对象随后可以被订阅\r\n- Stream对象中含有两个列表，一个是VideoTracks一个是AudioTracks用来存放视频数据和音频数据\r\n- 每一个VideoTrack或者AudioTrack中包含一个RingBuffer，用来存储发布者提供的数据，同时提供订阅者访问。\r\n- 具有订阅功能的插件，会通过GetStream函数获取到一个流，然后选择VideoTracks、AudioTracks里面的RingBuffer进行连续的读取\r\n\r\n# 发布插件如何发布流\r\n\r\n以rtmp协议为例子\r\n```go\r\nstream = \u0026engine.Stream{Type: \"RTMP\", StreamPath: streamPath}\r\nif stream.Publish() {\r\n  absTs := make(map[uint32]uint32)\r\n  vt := stream.NewVideoTrack(0)\r\n  at := stream.NewAudioTrack(0)\r\n  rec_audio = func(msg *Chunk) {\r\n    if msg.ChunkType == 0 {\r\n      absTs[msg.ChunkStreamID] = 0\r\n    }\r\n    if msg.Timestamp == 0xffffff {\r\n      absTs[msg.ChunkStreamID] += msg.ExtendTimestamp\r\n    } else {\r\n      absTs[msg.ChunkStreamID] += msg.Timestamp\r\n    }\r\n    at.PushByteStream(absTs[msg.ChunkStreamID], msg.Body)\r\n  }\r\n  rec_video = func(msg *Chunk) {\r\n    if msg.ChunkType == 0 {\r\n      absTs[msg.ChunkStreamID] = 0\r\n    }\r\n    if msg.Timestamp == 0xffffff {\r\n      absTs[msg.ChunkStreamID] += msg.ExtendTimestamp\r\n    } else {\r\n      absTs[msg.ChunkStreamID] += msg.Timestamp\r\n    }\r\n    vt.PushByteStream(absTs[msg.ChunkStreamID], msg.Body)\r\n  }\r\n  err = nc.SendMessage(SEND_STREAM_BEGIN_MESSAGE, nil)\r\n  err = nc.SendMessage(SEND_PUBLISH_START_MESSAGE, newPublishResponseMessageData(nc.streamID, NetStream_Publish_Start, Level_Status))\r\n} else {\r\n  err = nc.SendMessage(SEND_PUBLISH_RESPONSE_MESSAGE, newPublishResponseMessageData(nc.streamID, NetStream_Publish_BadName, Level_Error))\r\n}\r\n```\r\n默认会创建一个VideoTrack和一个AudioTrack\r\n当我们接收到数据的时候就可以朝里面填充物数据了\r\n\r\n在填充数据之前，需要获取到SPS和PPS，然后设置好，因为订阅者需要先发送这个数据\r\n然后通过Track到Push函数将数据填充到RingBuffer里面去\r\n\r\n# 订阅插件如何订阅流\r\n\r\n```go\r\nsub := Subscriber{ID: r.RemoteAddr, Type: \"FLV\", Ctx2: r.Context()}\r\nif err := sub.Subscribe(stringPath); err == nil {\r\n  vt, at := sub.WaitVideoTrack(), sub.WaitAudioTrack()\r\n  var buffer bytes.Buffer\r\n  if _, err := amf.WriteString(\u0026buffer, \"onMetaData\"); err != nil {\r\n    return\r\n  }\r\n  if vt != nil {\r\n    codec.WriteFLVTag(w, codec.FLV_TAG_TYPE_VIDEO, 0, vt.ExtraData.Payload)\r\n    sub.OnVideo = func(ts uint32, pack *VideoPack) {\r\n      codec.WriteFLVTag(w, codec.FLV_TAG_TYPE_VIDEO, ts, pack.Payload)\r\n    }\r\n  }\r\n  if at != nil {\r\n    if at.CodecID == 10 {\r\n      codec.WriteFLVTag(w, codec.FLV_TAG_TYPE_AUDIO, 0, at.ExtraData)\r\n    }\r\n    sub.OnAudio = func(ts uint32, pack *AudioPack) {\r\n      codec.WriteFLVTag(w, codec.FLV_TAG_TYPE_AUDIO, ts, pack.Payload)\r\n    }\r\n  }\r\n  sub.Play(at, vt)\r\n}\r\n```\r\n- 在发送数据前，需要先发送音视频的序列帧",
        "Version": "",
        "HotConfig": null
    },
    {
        "Name": "GateWay",
        "Config": "ListenAddr = \":8080\"\nCertFile = \"server.pem\"\nKeyFile = \"server.key\"\nListenAddrTLS = \":8082\"\nStaticPath = \"ui\"\n",
        "ReadMe": "# 网关插件\r\n\r\n该插件主要提供http协议访问，供其他插件公用http接口端口，并且提供一些基础的API\r\n\r\n## 插件地址\r\n\r\ngithub.com/Monibuca/plugin-gateway\r\n\r\n## 插件引入\r\n```go\r\nimport (\r\n    _ \"github.com/Monibuca/plugin-gateway\"\r\n)\r\n```\r\n\r\n## 默认插件配置\r\n```toml\r\n[GateWay]\r\nListenAddr = \":8080\"\r\n#ListenAddrTLS = \":8082\"\r\n#CertFile = \"xxx.cert\"\r\n#KeyFile = \"xxx.key\"\r\n#StaticPath = \"\"\r\n```\r\n- `ListenAddr` 公共http监听端口\r\n- `ListenAddrTLS` 公共https监听端口\r\n- `CertFile` https用的证书\r\n- `KeyFile` https用的证书的key\r\n- `StaticPath` 静态资源目录，设置后可以通过访问公共http监听端口来访问这些静态资源\r\n\r\n## 自带的API接口\r\n\r\n- `/api/gateway/sysInfo` 系统信息，包含版本号（Version）和启动时间（StartTime）两个字段\r\n- `/api/gateway/plugins` 所有插件信息，是一个数组里面包含插件的名称（Name）、版本（Version）、README（ReadMe）、配置（Config）、热更新配置（HotConfig）\r\n- `/api/gateway/config` 返回原始配置文件\r\n- `/api/gateway/stop?stream=xxx` 终止某一个流，入参是流标识（stream）\r\n- `/api/gateway/h264?stream=xxx\u0026len=10` 获取一段h264的流用于调试，入参数len代表需要获取的时长单位是秒\r\n- `/api/gateway/getIFrame?stream=xxx` 获取一个I帧数据，包含了SPS和PPS信息\r\n- `/api/gateway/modifyConfig?name=xxx\u0026key=xxx\u0026value=xxx` 修改可以热更新的配置,name是插件名（插件注册时设置）",
        "Version": "",
        "HotConfig": null
    },
    {
        "Name": "GB28181",
        "Config": "Serial = \"34020000002000000001\"\nRealm = \"3402000000\"\nListenAddr = \"192.168.1.120:5060\"\nExpires = 3600\nMediaPort = 58200\nAutoInvite = true\nAutoCloseAfter = -1\nTCP = false\nTCPMediaPortNum = 1\nRemoveBanInterval = 600\nPreFetchRecord = false\nUsername = \"\"\nPassword = \"\"\nUdpCacheSize = 0\n",
        "ReadMe": "# GB28181插件\r\n\r\n该插件提供SIP server的服务，以及流媒体服务器能力，可以将NVR和摄像头的流抓到m7s中，可获取的设备的录像数据以及访问录像视频。也可以控制摄像头的旋转、缩放等。\r\n\r\n## 插件地址\r\n\r\ngithub.com/Monibuca/plugin-gb28181\r\n\r\n## 插件引入\r\n\r\n```go\r\nimport (\r\n_ \"github.com/Monibuca/plugin-gb28181\"\r\n)\r\n```\r\n\r\n## 默认插件配置\r\n\r\n```toml\r\n[GB28181]\r\nSerial = \"34020000002000000001\"\r\nRealm = \"3402000000\"\r\nExpires = 3600\r\nListenAddr = \"127.0.0.1:5060\"\r\nAutoCloseAfter = -1\r\nAutoInvite = false\r\nMediaPort = 58200\r\nCatalogInterval = 30\r\nRemoveBanInterval = 600\r\nUsername = \"\"\r\nPassword = \"\"\r\nUdpCacheSize = 0 \r\nTCP = false\r\n```\r\n\r\n- `ListenAddr`是监听的地址，这里需要注意的是必须要带上Server的IP地址，这个IP地址是向设备发送信息的时候需要带上的。\r\n- `Serial` Server（SIP）的编号\r\n- `Realm` Server（SIP）的域\r\n- `AutoCloseAfter` 如果设置大于等于0，则当某个流最后一个订阅者取消订阅时会延迟N秒，会自动发送bye，节省流量。如果为了响应及时，可以设置成-1，保持流的连接\r\n- `AutoInvite` 表示自动发起invite，当Server（SIP）接收到设备信息时，立即向设备发送invite命令获取流\r\n- `MediaPort` 表示用于接收设备流的端口号\r\n- `CatalogInterval` 定时获取设备目录的间隔，单位秒\r\n- `RemoveBanInterval` 定时移除注册失败的设备黑名单，单位秒，默认10分钟（600秒）\r\n- `Username` 国标用户名\r\n- `Password` 国标密码\r\n- `TCP` 是否开启TCP接收国标流，默认false\r\n- `UdpCacheSize` 表示UDP缓存大小，默认为0，不开启。仅当TCP关闭，切缓存大于0时才开启，会最多缓存最多N个包，并排序，修复乱序造成的无法播放问题，注意开启后，会有一定的性能损耗，并丢失部分包。\r\n\r\n**注意某些摄像机没有设置用户名的地方，摄像机会以自身的国标id作为用户名，这个时候m7s会忽略使用摄像机的用户名，忽略配置的用户名**\r\n如果设备配置了错误的用户名和密码，连续三次上报错误后，m7s会记录设备id，并在10分钟内禁止设备注册\r\n\r\n## 插件功能\r\n\r\n### 使用SIP协议接受NVR或其他GB28181设备的注册\r\n\r\n- 服务器启动时自动监听SIP协议端口，当有设备注册时，会记录该设备信息，可以从UI的列表中看到设备\r\n- 定时发送Catalog命令查询设备的目录信息，可获得通道数据或者子设备\r\n- 发送RecordInfo命令查询设备对录像数据\r\n- 发送Invite命令获取设备的实时视频或者录像视频\r\n- 发送PTZ命令来控制摄像头云台\r\n\r\n### 作为GB28281的流媒体服务器接受设备的媒体流\r\n\r\n- 当invite设备的**实时**视频流时，会在m7s中创建对应的流，StreamPath由设备编号和通道编号组成，即[设备编号]/[通道编号],如果有多个层级，通道编号是最后一个层级的编号\r\n- 当invite设备的**录像**视频流时，StreamPath由设备编号和通道编号以及录像的起止时间拼接而成即[设备编号]/[通道编号]/[开始时间]-[结束时间]\r\n\r\n### 如何设置UDP缓存大小\r\n\r\n通过wireshark抓包，分析rtp，然后看一下大概多少个包可以有序\r\n\r\n## 接口API\r\n\r\n### 罗列所有的gb28181协议的设备\r\n\r\n`/api/gb28181/list`\r\n设备的结构体如下\r\n\r\n```go\r\ntype Device struct {\r\n*transaction.Core `json:\"-\"`\r\nID                string\r\nRegisterTime      time.Time\r\nUpdateTime        time.Time\r\nStatus            string\r\nChannels          []*Channel\r\nqueryChannel      bool\r\nsn                int\r\nfrom              *sip.Contact\r\nto                *sip.Contact\r\nAddr              string\r\nSipIP             string //暴露的IP\r\nchannelMap        map[string]*Channel\r\nchannelMutex      sync.RWMutex\r\n}\r\n```\r\n\r\n\u003e 根据golang的规则，小写字母开头的变量不会被序列化\r\n\r\n### 从设备拉取视频流\r\n\r\n`/api/gb28181/invite`\r\n\r\n参数名 | 必传 | 含义\r\n|----|---|---\r\nid|是 | 设备ID\r\nchannel|是|通道编号\r\nstartTime|否|开始时间（纯数字Unix时间戳）\r\nendTime|否|结束时间（纯数字Unix时间戳）\r\n\r\n返回200代表成功\r\n\r\n### 停止从设备拉流\r\n\r\n`/api/gb28181/bye`\r\n\r\n参数名 | 必传 | 含义\r\n|----|---|---\r\nid|是 | 设备ID\r\nchannel|是|通道编号\r\n\r\n### 发送控制命令\r\n\r\n`/api/gb28181/control`\r\n\r\n参数名 | 必传 | 含义\r\n|----|---|---\r\nid|是 | 设备ID\r\nchannel|是|通道编号\r\nptzcmd|是|PTZ控制指令\r\n\r\n### 查询录像\r\n\r\n`/api/gb28181/query/records`\r\n\r\n参数名 | 必传 | 含义\r\n|----|---|---\r\nid|是 | 设备ID\r\nchannel|是|通道编号\r\nstartTime|否|开始时间（字符串，格式：2021-7-23T12:00:00）\r\nendTime|否|结束时间（字符串格式同上）\r\n",
        "Version": "",
        "HotConfig": null
    },
    {
        "Name": "HDL",
        "Config": "ListenAddr = \"\"\nListenAddrTLS = \"\"\nCertFile = \"\"\nKeyFile = \"\"\nReconnect = false\n\n[AutoPullList]\n",
        "ReadMe": "# m7s核心引擎\r\n\r\n该项目为m7s的引擎部分，该部分逻辑是流媒体服务器的核心转发逻辑。仅包含最基础的功能，不含任何网络协议部分，但包含了一个插件的引入机制，其他功能均由插件实现\r\n\r\n# 引擎配置\r\n```toml\r\n[Engine]\r\nEnableAudio = true\r\nEnableVideo = true\r\n# 发布流默认过期时间单位秒\r\nPublishTimeout = 60\r\n# 自动关闭触发后延迟的秒数(期间内如果有新的订阅则取消触发关闭)\r\nAutoCloseDelay = 10\r\n# 启用RTP包乱序重排\r\nRTPReorder = false\r\n```\r\n\r\n# 引擎的基本功能\r\n- 引擎初始化会加载配置文件，并逐个调用插件的Run函数\r\n- 具有发布功能的插件，新建一个Stream对象，这个Stream对象随后可以被订阅\r\n- Stream对象中含有两个列表，一个是VideoTracks一个是AudioTracks用来存放视频数据和音频数据\r\n- 每一个VideoTrack或者AudioTrack中包含一个RingBuffer，用来存储发布者提供的数据，同时提供订阅者访问。\r\n- 具有订阅功能的插件，会通过GetStream函数获取到一个流，然后选择VideoTracks、AudioTracks里面的RingBuffer进行连续的读取\r\n\r\n# 发布插件如何发布流\r\n\r\n以rtmp协议为例子\r\n```go\r\nstream = \u0026engine.Stream{Type: \"RTMP\", StreamPath: streamPath}\r\nif stream.Publish() {\r\n  absTs := make(map[uint32]uint32)\r\n  vt := stream.NewVideoTrack(0)\r\n  at := stream.NewAudioTrack(0)\r\n  rec_audio = func(msg *Chunk) {\r\n    if msg.ChunkType == 0 {\r\n      absTs[msg.ChunkStreamID] = 0\r\n    }\r\n    if msg.Timestamp == 0xffffff {\r\n      absTs[msg.ChunkStreamID] += msg.ExtendTimestamp\r\n    } else {\r\n      absTs[msg.ChunkStreamID] += msg.Timestamp\r\n    }\r\n    at.PushByteStream(absTs[msg.ChunkStreamID], msg.Body)\r\n  }\r\n  rec_video = func(msg *Chunk) {\r\n    if msg.ChunkType == 0 {\r\n      absTs[msg.ChunkStreamID] = 0\r\n    }\r\n    if msg.Timestamp == 0xffffff {\r\n      absTs[msg.ChunkStreamID] += msg.ExtendTimestamp\r\n    } else {\r\n      absTs[msg.ChunkStreamID] += msg.Timestamp\r\n    }\r\n    vt.PushByteStream(absTs[msg.ChunkStreamID], msg.Body)\r\n  }\r\n  err = nc.SendMessage(SEND_STREAM_BEGIN_MESSAGE, nil)\r\n  err = nc.SendMessage(SEND_PUBLISH_START_MESSAGE, newPublishResponseMessageData(nc.streamID, NetStream_Publish_Start, Level_Status))\r\n} else {\r\n  err = nc.SendMessage(SEND_PUBLISH_RESPONSE_MESSAGE, newPublishResponseMessageData(nc.streamID, NetStream_Publish_BadName, Level_Error))\r\n}\r\n```\r\n默认会创建一个VideoTrack和一个AudioTrack\r\n当我们接收到数据的时候就可以朝里面填充物数据了\r\n\r\n在填充数据之前，需要获取到SPS和PPS，然后设置好，因为订阅者需要先发送这个数据\r\n然后通过Track到Push函数将数据填充到RingBuffer里面去\r\n\r\n# 订阅插件如何订阅流\r\n\r\n```go\r\nsub := Subscriber{ID: r.RemoteAddr, Type: \"FLV\", Ctx2: r.Context()}\r\nif err := sub.Subscribe(stringPath); err == nil {\r\n  vt, at := sub.WaitVideoTrack(), sub.WaitAudioTrack()\r\n  var buffer bytes.Buffer\r\n  if _, err := amf.WriteString(\u0026buffer, \"onMetaData\"); err != nil {\r\n    return\r\n  }\r\n  if vt != nil {\r\n    codec.WriteFLVTag(w, codec.FLV_TAG_TYPE_VIDEO, 0, vt.ExtraData.Payload)\r\n    sub.OnVideo = func(ts uint32, pack *VideoPack) {\r\n      codec.WriteFLVTag(w, codec.FLV_TAG_TYPE_VIDEO, ts, pack.Payload)\r\n    }\r\n  }\r\n  if at != nil {\r\n    if at.CodecID == 10 {\r\n      codec.WriteFLVTag(w, codec.FLV_TAG_TYPE_AUDIO, 0, at.ExtraData)\r\n    }\r\n    sub.OnAudio = func(ts uint32, pack *AudioPack) {\r\n      codec.WriteFLVTag(w, codec.FLV_TAG_TYPE_AUDIO, ts, pack.Payload)\r\n    }\r\n  }\r\n  sub.Play(at, vt)\r\n}\r\n```\r\n- 在发送数据前，需要先发送音视频的序列帧",
        "Version": "",
        "HotConfig": null
    },
    {
        "Name": "Record",
        "Config": "Path = \"resource\"\nAutoRecord = false\n",
        "ReadMe": "# record插件\nrecord plugin for monibuca\n\n实现了录制Flv文件的功能，并且支持再次使用录制好的Flv文件作为发布者进行发布。\n\n## 默认配置\n配置中的Path 表示要保存的Flv文件的根路径，可以使用相对路径或者绝对路径\n```toml\n[Record]\nPath = \"\"\nAutoRecord =false\n```\n\n## API\n\n- `/api/record/flv/list` 罗列所有录制的flv文件\n- `/api/record/flv?streamPath=live/rtc` 开始录制某个流\n- `/api/record/flv/stop?streamPath=live/rtc` 停止录制某个流\n- `/api/record/flv/play?streamPath=live/rtc` 将某个flv文件读取并发布成一个直播流\n- `/api/record/flv/delete?streamPath=live/rtc` 删除某个flv文件\n\n## 点播功能\n\n访问 http://[HOST]:[Gateway Port]/vod/live/rtc.flv 将会读取对应的flv文件",
        "Version": "v3.0.0-20210813073316-79dce1e0dc70",
        "HotConfig": [
            "AutoRecord"
        ]
    },
    {
        "Name": "RTMP",
        "Config": "ListenAddr = \":1935\"\nChunkSize = 512\n",
        "ReadMe": "# RTMP插件\n\n## 插件地址\n\ngithub.com/Monibuca/plugin-rtmp\n\n## 插件引入\n```go\nimport (\n    _ \"github.com/Monibuca/plugin-rtmp\"\n)\n```\n\n## 默认插件配置\n\n```toml\n[RTMP]\nListenAddr = \":1935\"\nChunkSize = 512\n```\n\n- ListenAddr是监听的地址\n- ChunkSize是分块大小\n\n## 插件功能\n\n### 接收RTMP协议的推流\n\n例如通过ffmpeg向m7s进行推流\n\n```bash\nffmpeg -i **** -f flv rtmp://localhost/live/test\n```\n\n会在m7s内部形成一个名为live/test的流\n\n### 从m7s拉取rtmp协议流\n如果m7s中已经存在live/test流的话就可以用rtmp协议进行播放\n```bash\nffplay -i rtmp://localhost/live/test\n```",
        "Version": "v3.0.0",
        "HotConfig": null
    }
]